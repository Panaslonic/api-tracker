"""
API Watcher V2 - Enhanced version with DB, ZenRows, Gemini AI and Slack
–£–ª—É—á—à–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è —Å –ë–î, ZenRows, Gemini AI –∏ Slack –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–µ–π
"""

import json
import logging
from typing import Dict, List, Optional
from datetime import datetime, timedelta

from api_watcher.config import Config
from api_watcher.storage.database import DatabaseManager
from api_watcher.utils.zenrows_client import ZenRowsClient
from api_watcher.utils.gemini_analyzer import GeminiAnalyzer
from api_watcher.utils.openrouter_analyzer import OpenRouterAnalyzer
from api_watcher.utils.smart_comparator import SmartComparator
from api_watcher.utils.docs_finder import find_api_documentation
from api_watcher.notifier.slack_notifier import SlackNotifier
from api_watcher.notifier.webhook_notifier import WebhookNotifier
from api_watcher.parsers.openapi_parser import OpenAPIParser
from api_watcher.parsers.json_parser import JSONParser
import asyncio

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class APIWatcherV2:
    """–£–ª—É—á—à–µ–Ω–Ω—ã–π –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ API —Å AI-–∞–Ω–∞–ª–∏–∑–æ–º"""
    
    def __init__(self):
        self.config = Config
        self.db = DatabaseManager(self.config.DATABASE_URL)
        self.comparator = SmartComparator()
        
        # –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
        self.zenrows = None
        if self.config.is_zenrows_configured():
            self.zenrows = ZenRowsClient(self.config.ZENROWS_API_KEY)
            logger.info("‚úÖ ZenRows –∫–ª–∏–µ–Ω—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        
        # AI Analyzer - –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç OpenRouter, fallback –Ω–∞ Gemini
        self.ai_analyzer = None
        if self.config.is_openrouter_configured():
            self.ai_analyzer = OpenRouterAnalyzer(
                self.config.OPENROUTER_API_KEY,
                self.config.OPENROUTER_MODEL,
                self.config.OPENROUTER_SITE_URL,
                self.config.OPENROUTER_APP_NAME
            )
            logger.info(f"‚úÖ OpenRouter AI –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω (–º–æ–¥–µ–ª—å: {self.config.OPENROUTER_MODEL})")
        elif self.config.is_gemini_configured():
            self.ai_analyzer = GeminiAnalyzer(
                self.config.GEMINI_API_KEY,
                self.config.GEMINI_MODEL
            )
            logger.info("‚úÖ Gemini AI –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω (fallback)")
        
        self.slack = None
        if self.config.is_slack_configured():
            self.slack = SlackNotifier(
                self.config.SLACK_BOT_TOKEN,
                self.config.SLACK_CHANNEL
            )
            logger.info("‚úÖ Slack notifier –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        
        self.webhook = None
        if self.config.is_webhook_configured():
            self.webhook = WebhookNotifier(self.config.WEBHOOK_URL)
            logger.info("‚úÖ Webhook notifier –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
            # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ
            if not self.webhook.test_connection():
                logger.warning("‚ö†Ô∏è Webhook –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –Ω–æ –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è")
        
        self.openapi_parser = OpenAPIParser()
        self.json_parser = JSONParser()
    
    def fetch_content(self, url: str) -> Optional[str]:
        """–ü–æ–ª—É—á–∞–µ—Ç –∫–æ–Ω—Ç–µ–Ω—Ç URL (—á–µ—Ä–µ–∑ ZenRows –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω)"""
        if self.zenrows:
            logger.info(f"üåê –ü–æ–ª—É—á–∞–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç —á–µ—Ä–µ–∑ ZenRows: {url}")
            return self.zenrows.fetch_with_fallback(url)
        else:
            logger.info(f"üåê –ü–æ–ª—É—á–∞–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç –Ω–∞–ø—Ä—è–º—É—é: {url}")
            import requests
            try:
                response = requests.get(url, timeout=30)
                response.raise_for_status()
                return response.text
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è {url}: {e}")
                return None
    
    def _is_valid_response(self, content: str, url: str) -> bool:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å –æ—Ç–≤–µ—Ç–∞
        
        Args:
            content: –ö–æ–Ω—Ç–µ–Ω—Ç –æ—Ç–≤–µ—Ç–∞
            url: URL –∑–∞–ø—Ä–æ—Å–∞
            
        Returns:
            True –µ—Å–ª–∏ –æ—Ç–≤–µ—Ç –≤–∞–ª–∏–¥–Ω—ã–π, False –µ—Å–ª–∏ –Ω—É–∂–Ω–æ –∏—Å–∫–∞—Ç—å –Ω–æ–≤—É—é –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é
        """
        if not content:
            return False
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ —Ç–∏–ø–∏—á–Ω—ã–µ –æ—à–∏–±–∫–∏
        error_indicators = [
            '404',
            'not found',
            'page not found',
            'error',
            'forbidden',
            '403',
            '500',
            'internal server error',
            'service unavailable',
            'bad gateway'
        ]
        
        content_lower = content.lower()
        
        # –ï—Å–ª–∏ –∫–æ–Ω—Ç–µ–Ω—Ç —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π (–º–µ–Ω—å—à–µ 100 —Å–∏–º–≤–æ–ª–æ–≤) - –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–æ
        if len(content) < 100:
            logger.warning(f"‚ö†Ô∏è –ü–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–æ –∫–æ—Ä–æ—Ç–∫–∏–π –æ—Ç–≤–µ—Ç ({len(content)} —Å–∏–º–≤–æ–ª–æ–≤)")
            return False
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –æ—à–∏–±–æ–∫
        for indicator in error_indicators:
            if indicator in content_lower:
                logger.warning(f"‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä –æ—à–∏–±–∫–∏: {indicator}")
                return False
        
        return True
    
    async def _try_find_new_documentation(
        self,
        url: str,
        api_name: Optional[str],
        method_name: Optional[str]
    ) -> Optional[str]:
        """
        –ü—ã—Ç–∞–µ—Ç—Å—è –Ω–∞–π—Ç–∏ –Ω–æ–≤—É—é –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é –¥–ª—è API
        
        Args:
            url: –°—Ç–∞—Ä—ã–π URL
            api_name: –ù–∞–∑–≤–∞–Ω–∏–µ API
            method_name: –ù–∞–∑–≤–∞–Ω–∏–µ –º–µ—Ç–æ–¥–∞
            
        Returns:
            –ù–æ–≤—ã–π URL –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –∏–ª–∏ None
        """
        logger.info(f"üîç –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ –Ω–æ–≤—É—é –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é –¥–ª—è {api_name or url}")
        
        try:
            docs_info = await find_api_documentation(
                url=url,
                api_name=api_name,
                method_name=method_name,
                serpapi_key=self.config.SERPAPI_KEY
            )
            
            if docs_info and docs_info.get('url'):
                new_url = docs_info['url']
                doc_type = docs_info.get('type', 'unknown')
                
                logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω–∞ –Ω–æ–≤–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è ({doc_type}): {new_url}")
                
                # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è
                if self.slack:
                    message = f"üîÑ *–û–±–Ω–æ–≤–ª–µ–Ω–∞ —Å—Å—ã–ª–∫–∞ –Ω–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é*\n\n"
                    message += f"*API:* {api_name or 'Unknown'}\n"
                    if method_name:
                        message += f"*–ú–µ—Ç–æ–¥:* {method_name}\n"
                    message += f"*–°—Ç–∞—Ä—ã–π URL:* {url}\n"
                    message += f"*–ù–æ–≤—ã–π URL:* {new_url}\n"
                    message += f"*–¢–∏–ø:* {doc_type}\n"
                    
                    if docs_info.get('title'):
                        message += f"*–ó–∞–≥–æ–ª–æ–≤–æ–∫:* {docs_info['title']}\n"
                    
                    self.slack.send_message(message)
                
                if self.webhook:
                    self.webhook.send_documentation_update(
                        api_name=api_name or 'Unknown',
                        method_name=method_name,
                        old_url=url,
                        new_url=new_url,
                        doc_type=doc_type
                    )
                
                return new_url
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –Ω–æ–≤–æ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏: {e}")
        
        return None
    
    def detect_content_type(self, url: str, content: str) -> str:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–∏–ø –∫–æ–Ω—Ç–µ–Ω—Ç–∞"""
        if 'openapi' in url.lower() or 'swagger' in url.lower():
            return 'openapi'
        
        try:
            data = json.loads(content)
            if 'openapi' in data or 'swagger' in data:
                return 'openapi'
            return 'json'
        except:
            return 'html'
    
    def process_url(
        self,
        url: str,
        api_name: Optional[str] = None,
        method_name: Optional[str] = None
    ) -> Dict:
        """
        –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ–¥–∏–Ω URL: –ø–æ–ª—É—á–∞–µ—Ç –∫–æ–Ω—Ç–µ–Ω—Ç, —Å—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç, –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç
        
        Returns:
            {
                'url': str,
                'has_changes': bool,
                'summary': str,
                'severity': str
            }
        """
        logger.info(f"\n{'='*60}")
        logger.info(f"üîç –û–±—Ä–∞–±–æ—Ç–∫–∞: {api_name or url}")
        logger.info(f"{'='*60}")
        
        # 1. –ü–æ–ª—É—á–∞–µ–º –Ω–æ–≤—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç
        new_html = self.fetch_content(url)
        if not new_html:
            logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∫–æ–Ω—Ç–µ–Ω—Ç –¥–ª—è {url}")
            return {'url': url, 'has_changes': False, 'error': 'Failed to fetch'}
        
        # 1.5. –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å –æ—Ç–≤–µ—Ç–∞
        if not self._is_valid_response(new_html, url):
            logger.warning(f"‚ö†Ô∏è –ù–µ–≤–∞–ª–∏–¥–Ω—ã–π –æ—Ç–≤–µ—Ç –æ—Ç {url}, –ø—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ –Ω–æ–≤—É—é –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é")
            
            # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ –Ω–æ–≤—É—é –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é
            new_url = asyncio.run(self._try_find_new_documentation(url, api_name, method_name))
            
            if new_url:
                # –ü—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å –∫–æ–Ω—Ç–µ–Ω—Ç —Å –Ω–æ–≤–æ–≥–æ URL
                new_html_from_new_url = self.fetch_content(new_url)
                
                if new_html_from_new_url and self._is_valid_response(new_html_from_new_url, new_url):
                    logger.info(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –ø–æ–ª—É—á–µ–Ω –∫–æ–Ω—Ç–µ–Ω—Ç —Å –Ω–æ–≤–æ–≥–æ URL: {new_url}")
                    # –û–±–Ω–æ–≤–ª—è–µ–º URL –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
                    url = new_url
                    new_html = new_html_from_new_url
                else:
                    logger.error(f"‚ùå –ù–æ–≤—ã–π URL —Ç–∞–∫–∂–µ –≤–µ—Ä–Ω—É–ª –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–π –æ—Ç–≤–µ—Ç")
                    return {'url': url, 'has_changes': False, 'error': 'Invalid response, new URL also failed'}
            else:
                logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –Ω–æ–≤—É—é –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é")
                return {'url': url, 'has_changes': False, 'error': 'Invalid response, no alternative found'}
        
        # 2. –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –∫–æ–Ω—Ç–µ–Ω—Ç–∞
        content_type = self.detect_content_type(url, new_html)
        logger.info(f"üìÑ –¢–∏–ø –∫–æ–Ω—Ç–µ–Ω—Ç–∞: {content_type}")
        
        # 3. –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—ã–¥—É—â–∏–π —Å–Ω—ç–ø—à–æ—Ç
        old_snapshot = self.db.get_latest_snapshot(url)
        
        if not old_snapshot:
            logger.info(f"üìù –ü–µ—Ä–≤—ã–π —Å–Ω—ç–ø—à–æ—Ç –¥–ª—è {url}")
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–µ—Ä–≤—ã–π —Å–Ω—ç–ø—à–æ—Ç
            text_content = self.comparator.html_to_text(new_html) if content_type == 'html' else new_html
            content_hash = self.comparator.calculate_hash(new_html)
            
            self.db.save_snapshot(
                url=url,
                raw_html=new_html,
                text_content=text_content,
                api_name=api_name,
                method_name=method_name,
                content_type=content_type,
                content_hash=content_hash,
                has_changes=False
            )
            
            return {
                'url': url,
                'has_changes': False,
                'is_first_snapshot': True
            }
        
        # 4. –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç
        result = self._compare_content(
            old_snapshot,
            new_html,
            content_type,
            url,
            api_name,
            method_name
        )
        
        return result
    
    def _compare_content(
        self,
        old_snapshot,
        new_html: str,
        content_type: str,
        url: str,
        api_name: Optional[str],
        method_name: Optional[str]
    ) -> Dict:
        """–°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç –∫–æ–Ω—Ç–µ–Ω—Ç –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞"""
        
        if content_type == 'openapi':
            return self._compare_openapi(
                old_snapshot, new_html, url, api_name, method_name
            )
        elif content_type == 'json':
            return self._compare_json(
                old_snapshot, new_html, url, api_name, method_name
            )
        else:  # html
            return self._compare_html(
                old_snapshot, new_html, url, api_name, method_name
            )
    
    def _compare_openapi(
        self,
        old_snapshot,
        new_html: str,
        url: str,
        api_name: Optional[str],
        method_name: Optional[str]
    ) -> Dict:
        """–°—Ä–∞–≤–Ω–µ–Ω–∏–µ OpenAPI —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–π"""
        logger.info("üîç –°—Ä–∞–≤–Ω–µ–Ω–∏–µ OpenAPI —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–∏...")
        
        try:
            # –ü–∞—Ä—Å–∏–º —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–∏
            old_spec = json.loads(old_snapshot.structured_data) if old_snapshot.structured_data else json.loads(old_snapshot.raw_html)
            new_spec = json.loads(new_html)
            
            # –°—Ç—Ä—É–∫—Ç—É—Ä–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ
            has_changes, changes_dict = self.comparator.compare_openapi(old_spec, new_spec)
            
            if not has_changes:
                logger.info("‚úÖ –ò–∑–º–µ–Ω–µ–Ω–∏–π –≤ OpenAPI –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ")
                return {'url': url, 'has_changes': False}
            
            logger.info("üîç –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ OpenAPI")
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º severity –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–π (–±–µ–∑ AI)
            categories = self.comparator.categorize_openapi_changes(changes_dict)
            if categories['breaking_changes']:
                severity = 'major'
            elif categories['new_endpoints'] or categories['removed_endpoints']:
                severity = 'moderate'
            else:
                severity = 'minor'
            
            # AI –∞–Ω–∞–ª–∏–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π - –¢–û–õ–¨–ö–û –µ—Å–ª–∏ –µ—Å—Ç—å –∑–Ω–∞—á–∏–º—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è
            ai_summary = "–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ OpenAPI —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–∏"
            
            if self.ai_analyzer and changes_dict and (severity in ['moderate', 'major']):
                logger.info(f"ü§ñ –ó–∞–ø—É—Å–∫–∞–µ–º AI –∞–Ω–∞–ª–∏–∑ (severity: {severity})...")
                ai_summary = self.ai_analyzer.analyze_openapi_changes(changes_dict, api_name)
            else:
                if severity == 'minor':
                    logger.info("‚ÑπÔ∏è –ù–µ–∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º AI –∞–Ω–∞–ª–∏–∑")
                    # –ü—Ä–æ—Å—Ç–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –¥–ª—è minor –∏–∑–º–µ–Ω–µ–Ω–∏–π
                    change_count = len(changes_dict.get('modified', []))
                    ai_summary = f"–ù–µ–∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ OpenAPI —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–∏ ({change_count} —ç–ª–µ–º–µ–Ω—Ç–æ–≤)"
                

            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–æ–≤—ã–π —Å–Ω—ç–ø—à–æ—Ç
            content_hash = self.comparator.calculate_hash(new_html)
            self.db.save_snapshot(
                url=url,
                raw_html=new_html,
                text_content=json.dumps(new_spec, indent=2),
                api_name=api_name,
                method_name=method_name,
                content_type='openapi',
                structured_data=new_spec,
                content_hash=content_hash,
                has_changes=True,
                ai_summary=ai_summary
            )
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è
            if self.slack:
                self.slack.send_change_notification(
                    api_name=api_name or 'Unknown API',
                    method_name=method_name,
                    url=url,
                    summary=ai_summary,
                    severity=severity
                )
            
            if self.webhook:
                self.webhook.send_change_notification(
                    api_name=api_name or 'Unknown API',
                    method_name=method_name,
                    url=url,
                    summary=ai_summary,
                    severity=severity
                )
            
            return {
                'url': url,
                'has_changes': True,
                'summary': ai_summary,
                'severity': severity,
                'changes': changes_dict
            }
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è OpenAPI: {e}")
            return {'url': url, 'has_changes': False, 'error': str(e)}
    
    def _compare_json(
        self,
        old_snapshot,
        new_html: str,
        url: str,
        api_name: Optional[str],
        method_name: Optional[str]
    ) -> Dict:
        """–°—Ä–∞–≤–Ω–µ–Ω–∏–µ JSON –¥–∞–Ω–Ω—ã—Ö"""
        logger.info("üîç –°—Ä–∞–≤–Ω–µ–Ω–∏–µ JSON –¥–∞–Ω–Ω—ã—Ö...")
        
        try:
            old_data = json.loads(old_snapshot.structured_data) if old_snapshot.structured_data else json.loads(old_snapshot.raw_html)
            new_data = json.loads(new_html)
            
            has_changes, changes_dict = self.comparator.compare_json(old_data, new_data)
            
            if not has_changes:
                logger.info("‚úÖ –ò–∑–º–µ–Ω–µ–Ω–∏–π –≤ JSON –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ")
                return {'url': url, 'has_changes': False}
            
            logger.info("üîç –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ JSON")
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–æ–≤—ã–π —Å–Ω—ç–ø—à–æ—Ç
            content_hash = self.comparator.calculate_hash(new_html)
            summary = f"–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ JSON —Å—Ç—Ä—É–∫—Ç—É—Ä–µ: {len(changes_dict)} –∏–∑–º–µ–Ω–µ–Ω–∏–π"
            
            self.db.save_snapshot(
                url=url,
                raw_html=new_html,
                text_content=json.dumps(new_data, indent=2),
                api_name=api_name,
                method_name=method_name,
                content_type='json',
                structured_data=new_data,
                content_hash=content_hash,
                has_changes=True,
                ai_summary=summary
            )
            
            return {
                'url': url,
                'has_changes': True,
                'summary': summary,
                'severity': 'moderate'
            }
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è JSON: {e}")
            return {'url': url, 'has_changes': False, 'error': str(e)}
    
    def _compare_html(
        self,
        old_snapshot,
        new_html: str,
        url: str,
        api_name: Optional[str],
        method_name: Optional[str]
    ) -> Dict:
        """–°—Ä–∞–≤–Ω–µ–Ω–∏–µ HTML –∫–æ–Ω—Ç–µ–Ω—Ç–∞ —Å AI –∞–Ω–∞–ª–∏–∑–æ–º"""
        logger.info("üîç –°—Ä–∞–≤–Ω–µ–Ω–∏–µ HTML –∫–æ–Ω—Ç–µ–Ω—Ç–∞...")
        
        # –ë—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ —Ö–µ—à—É
        new_hash = self.comparator.calculate_hash(new_html)
        if old_snapshot.content_hash == new_hash:
            logger.info("‚úÖ –ö–æ–Ω—Ç–µ–Ω—Ç –Ω–µ –∏–∑–º–µ–Ω–∏–ª—Å—è (–ø–æ —Ö–µ—à—É)")
            return {'url': url, 'has_changes': False}
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —Ç–µ–∫—Å—Ç
        has_changes, old_text, new_text = self.comparator.compare_html_text(
            old_snapshot.raw_html,
            new_html
        )
        
        if not has_changes:
            logger.info("‚úÖ –ò–∑–º–µ–Ω–µ–Ω–∏–π –≤ —Ç–µ–∫—Å—Ç–µ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ")
            return {'url': url, 'has_changes': False}
        
        logger.info("üîç –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ HTML")
        
        # AI –∞–Ω–∞–ª–∏–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π - –¢–û–õ–¨–ö–û –µ—Å–ª–∏ –Ω–∞—Å—Ç—Ä–æ–µ–Ω AI analyzer
        ai_result = {'has_significant_changes': True, 'summary': '–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –∏–∑–º–µ–Ω–µ–Ω–∏—è', 'severity': 'moderate'}
        
        if self.ai_analyzer:
            logger.info("ü§ñ –ó–∞–ø—É—Å–∫–∞–µ–º AI –∞–Ω–∞–ª–∏–∑ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∑–Ω–∞—á–∏–º–æ—Å—Ç–∏...")
            ai_result = self.ai_analyzer.analyze_changes(
                old_text,
                new_text,
                api_name,
                method_name
            )
        else:
            logger.info("‚ÑπÔ∏è AI analyzer –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω, —Å—á–∏—Ç–∞–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏—è –∑–Ω–∞—á–∏–º—ã–º–∏")
        
        if not ai_result.get('has_significant_changes'):
            logger.info("‚ÑπÔ∏è AI –æ–ø—Ä–µ–¥–µ–ª–∏–ª –∏–∑–º–µ–Ω–µ–Ω–∏—è –∫–∞–∫ –Ω–µ–∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–µ")
            # –í—Å–µ —Ä–∞–≤–Ω–æ —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Å–Ω—ç–ø—à–æ—Ç, –Ω–æ –Ω–µ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ
            self.db.save_snapshot(
                url=url,
                raw_html=new_html,
                text_content=new_text,
                api_name=api_name,
                method_name=method_name,
                content_type='html',
                content_hash=new_hash,
                has_changes=False,
                ai_summary="–ù–µ–∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è"
            )
            return {'url': url, 'has_changes': False, 'reason': 'insignificant'}
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–Ω—ç–ø—à–æ—Ç —Å –∏–∑–º–µ–Ω–µ–Ω–∏—è–º–∏
        summary = ai_result.get('summary', '–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã —Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è')
        severity = ai_result.get('severity', 'moderate')
        
        self.db.save_snapshot(
            url=url,
            raw_html=new_html,
            text_content=new_text,
            api_name=api_name,
            method_name=method_name,
            content_type='html',
            content_hash=new_hash,
            has_changes=True,
            ai_summary=summary
        )
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è
        if self.slack:
            self.slack.send_change_notification(
                api_name=api_name or 'Unknown API',
                method_name=method_name,
                url=url,
                summary=summary,
                severity=severity,
                key_changes=ai_result.get('key_changes', [])
            )
        
        if self.webhook:
            self.webhook.send_change_notification(
                api_name=api_name or 'Unknown API',
                method_name=method_name,
                url=url,
                summary=summary,
                severity=severity,
                key_changes=ai_result.get('key_changes', [])
            )
        
        return {
            'url': url,
            'has_changes': True,
            'summary': summary,
            'severity': severity,
            'key_changes': ai_result.get('key_changes', [])
        }
    
    def process_urls_file(self, urls_file: str) -> List[Dict]:
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Ñ–∞–π–ª —Å URL-–∞–º–∏"""
        logger.info(f"üìÇ –ó–∞–≥—Ä—É–∂–∞–µ–º URLs –∏–∑ {urls_file}")
        
        try:
            with open(urls_file, 'r', encoding='utf-8') as f:
                urls_data = json.load(f)
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞ {urls_file}: {e}")
            return []
        
        results = []
        
        for item in urls_data:
            url = item.get('url')
            api_name = item.get('api_name')
            method_name = item.get('method_name')
            
            if not url:
                continue
            
            result = self.process_url(url, api_name, method_name)
            results.append(result)
        
        return results
    
    def send_weekly_digest(self):
        """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –µ–∂–µ–Ω–µ–¥–µ–ª—å–Ω—É—é —Å–≤–æ–¥–∫—É –∏–∑–º–µ–Ω–µ–Ω–∏–π"""
        if not self.slack:
            logger.warning("‚ö†Ô∏è Slack –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –µ–∂–µ–Ω–µ–¥–µ–ª—å–Ω—É—é —Å–≤–æ–¥–∫—É")
            return
        
        logger.info("üìä –§–æ—Ä–º–∏—Ä—É–µ–º –µ–∂–µ–Ω–µ–¥–µ–ª—å–Ω—É—é —Å–≤–æ–¥–∫—É...")
        
        snapshots = self.db.get_snapshots_with_changes(days=self.config.CHECK_INTERVAL_DAYS)
        
        changes = []
        for snapshot in snapshots:
            changes.append({
                'api_name': snapshot.api_name,
                'method_name': snapshot.method_name,
                'url': snapshot.url,
                'summary': snapshot.ai_summary or '–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –∏–∑–º–µ–Ω–µ–Ω–∏—è',
                'created_at': snapshot.created_at
            })
        
        self.slack.send_weekly_digest(changes)
    
    def cleanup(self):
        """–û—á–∏—Å—Ç–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤"""
        self.db.close()


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    watcher = APIWatcherV2()
    
    try:
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º URLs
        results = watcher.process_urls_file(Config.URLS_FILE)
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        total = len(results)
        changed = sum(1 for r in results if r.get('has_changes'))
        
        logger.info(f"\n{'='*60}")
        logger.info(f"üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê")
        logger.info(f"{'='*60}")
        logger.info(f"–í—Å–µ–≥–æ –ø—Ä–æ–≤–µ—Ä–µ–Ω–æ: {total}")
        logger.info(f"–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –∏–∑–º–µ–Ω–µ–Ω–∏–π: {changed}")
        logger.info(f"{'='*60}\n")
        
    finally:
        watcher.cleanup()


if __name__ == '__main__':
    main()
